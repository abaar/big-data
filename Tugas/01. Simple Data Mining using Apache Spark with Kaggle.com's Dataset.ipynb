{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset\n",
    "\n",
    "1. Data used : Seattle Checkouts by Title (6.62GB After Extraction) [ https://www.kaggle.com/city-of-seattle/seattle-checkouts-by-title ]\n",
    "2. Description : This dataset includes a monthly count of Seattle Public Library checkouts by title for physical and electronic items. The dataset begins with checkouts that occurred in April 2005."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initiating Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"simple data mining\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pyspark.sql.session.SparkSession object at 0x000002EF525AC390>\n"
     ]
    }
   ],
   "source": [
    "#test wheter spark successfully created or not\n",
    "print(spark)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv(\"D:/Repos/Resource/Lib-Checkout/checkouts-by-title.csv\", header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32723545"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#counting rows\n",
    "\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType(List(StructField(UsageClass,StringType,true),StructField(CheckoutType,StringType,true),StructField(MaterialType,StringType,true),StructField(CheckoutYear,IntegerType,true),StructField(CheckoutMonth,IntegerType,true),StructField(Checkouts,IntegerType,true),StructField(Title,StringType,true),StructField(Creator,StringType,true),StructField(Subjects,StringType,true),StructField(Publisher,StringType,true),StructField(PublicationYear,StringType,true)))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#show schema\n",
    "\n",
    "df.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating datas as a temporary SQL View\n",
    "\n",
    "df.createOrReplaceTempView('libchecksout')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Data Mining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Show which material type has the most record\n",
    "\n",
    "mattype = spark.sql(\"SELECT MaterialType , SUM(Checkouts) AS TOTAL \\\n",
    "                        FROM libchecksout \\\n",
    "                        GROUP BY MaterialType \\\n",
    "                        ORDER BY TOTAL DESC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------+\n",
      "|        MaterialType|   TOTAL|\n",
      "+--------------------+--------+\n",
      "|                BOOK|54356026|\n",
      "|           VIDEODISC|28766230|\n",
      "|           SOUNDDISC|13710478|\n",
      "|               EBOOK| 8923137|\n",
      "|           AUDIOBOOK| 3773748|\n",
      "|           VIDEOCASS| 1524029|\n",
      "|                SONG| 1311618|\n",
      "|               MUSIC|  364926|\n",
      "|            MAGAZINE|  361322|\n",
      "|           SOUNDCASS|  330665|\n",
      "|               MIXED|  253790|\n",
      "|               MOVIE|  212605|\n",
      "|                  CR|  172233|\n",
      "|SOUNDDISC, VIDEODISC|  133863|\n",
      "|              VISUAL|  110539|\n",
      "|          TELEVISION|   87831|\n",
      "|            SOUNDREC|   76105|\n",
      "|               VIDEO|   71701|\n",
      "|               COMIC|   43928|\n",
      "|                 KIT|   43737|\n",
      "+--------------------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mattype.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#show the most top publisher each year\n",
    "\n",
    "mostpublisher = spark.sql(\"SELECT CheckoutYear , Publisher, SUM(Checkouts) AS Total \\\n",
    "                            FROM libchecksout \\\n",
    "                            GROUP BY CheckoutYear, Publisher \\\n",
    "                            ORDER BY Total DESC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------------------+-------+\n",
      "|CheckoutYear|           Publisher|  Total|\n",
      "+------------+--------------------+-------+\n",
      "|        2006|                null|4061261|\n",
      "|        2008|                null|3971560|\n",
      "|        2007|                null|3735222|\n",
      "|        2009|                null|2880721|\n",
      "|        2010|                null|2528459|\n",
      "|        2005|                null|2491331|\n",
      "|        2011|                null|1943663|\n",
      "|        2012|                null|1313496|\n",
      "|        2013|                null| 901746|\n",
      "|        2014|                null| 550253|\n",
      "|        2015|                null| 468948|\n",
      "|        2018|  Random House, Inc.| 444055|\n",
      "|        2016|  Random House, Inc.| 381015|\n",
      "|        2015|  Random House, Inc.| 380639|\n",
      "|        2017|  Random House, Inc.| 359447|\n",
      "|        2016|                null| 334879|\n",
      "|        2018|HarperCollins Pub...| 323504|\n",
      "|        2018|Penguin Group (US...| 308035|\n",
      "|        2014|  Random House, Inc.| 304388|\n",
      "|        2018|       Books on Tape| 279857|\n",
      "+------------+--------------------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mostpublisher.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#show the most rapid growth of checkouts of the library's properties in 2017-2018\n",
    "\n",
    "rapidprops = spark.sql(\"SELECT SUM(Checkouts) as Total , Title \\\n",
    "                        FROM libchecksout \\\n",
    "                        WHERE CheckoutYear BETWEEN 2017 AND 2018 \\\n",
    "                        GROUP BY Title \\\n",
    "                        ORDER BY Total DESC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+\n",
      "|Total|               Title|\n",
      "+-----+--------------------+\n",
      "|11404|In Building Devic...|\n",
      "|10900|      The New Yorker|\n",
      "|10296|SPL HotSpot : con...|\n",
      "| 9868|The hate u give /...|\n",
      "| 9267|  FlexTech--Laptops.|\n",
      "| 6543|           Us Weekly|\n",
      "| 6331|       The Economist|\n",
      "| 6006|SPL HotSpot : con...|\n",
      "| 5904|Lion / The Weinst...|\n",
      "| 5860|Hillbilly Elegy: ...|\n",
      "| 5718|Educated : a memo...|\n",
      "| 5711|The woman in the ...|\n",
      "| 5485|Evicted : poverty...|\n",
      "| 5234|Arrival / Paramou...|\n",
      "| 5067|Little Fires Ever...|\n",
      "| 4946|The Goldfinch: A ...|\n",
      "| 4942|Manchester by the...|\n",
      "| 4911|The power : a nov...|\n",
      "| 4817|Lincoln in the ba...|\n",
      "| 4801|So you want to ta...|\n",
      "+-----+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rapidprops.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export and Simple Data Mining\n",
    "\n",
    "Let's say i want to see the growth of the record of the first row's Title of the 3rd example each year.\n",
    "So i need to export it first since i can't see it well on notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export it into a csv file\n",
    "\n",
    "rapidprops.coalesce(1).write.csv(\"C:/Repos/jupyternotes/Resource/most-rapid-growth-in-2017-2018.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the result is \"In Building Device Checkout\"\n",
    "# lets find its growth each year start from the very beginning its checked out.\n",
    "\n",
    "yearlygrowth = spark.sql(\"SELECT DISTINCT CheckoutYear,Title, SUM(Checkouts) FROM libchecksout WHERE Title='In Building Device Checkout' GROUP BY CheckoutYear, Title ORDER BY CheckoutYear ASC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------------------+--------------+\n",
      "|CheckoutYear|               Title|sum(Checkouts)|\n",
      "+------------+--------------------+--------------+\n",
      "|        2013|In Building Devic...|            12|\n",
      "|        2014|In Building Devic...|           298|\n",
      "|        2015|In Building Devic...|           318|\n",
      "|        2016|In Building Devic...|          2467|\n",
      "|        2017|In Building Devic...|          5401|\n",
      "|        2018|In Building Devic...|          6003|\n",
      "+------------+--------------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "yearlygrowth.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
