{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset\n",
    "\n",
    "1. Data used : Seattle Checkouts by Title (6.62GB After Extraction) [ https://www.kaggle.com/city-of-seattle/seattle-checkouts-by-title ]\n",
    "\n",
    "2. Description : This dataset includes a monthly count of Seattle Public Library checkouts by title for physical and electronic items. The dataset begins with checkouts that occurred in April 2005."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initiating Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"simple data clustering\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pyspark.sql.session.SparkSession object at 0x000001DEE587A9B0>\n"
     ]
    }
   ],
   "source": [
    "#test wheter spark successfully created or not\n",
    "print(spark)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv(\"D:/Repos/Resource/Lib-Checkout/checkouts-by-title.csv\", header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32723545"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#counting rows\n",
    "\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType(List(StructField(UsageClass,StringType,true),StructField(CheckoutType,StringType,true),StructField(MaterialType,StringType,true),StructField(CheckoutYear,IntegerType,true),StructField(CheckoutMonth,IntegerType,true),StructField(Checkouts,IntegerType,true),StructField(Title,StringType,true),StructField(Creator,StringType,true),StructField(Subjects,StringType,true),StructField(Publisher,StringType,true),StructField(PublicationYear,StringType,true)))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#show schema\n",
    "\n",
    "df.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating datas as a temporary SQL View\n",
    "\n",
    "df.createOrReplaceTempView('libchecksout')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Machine Learning\n",
    "\n",
    "Let's say we are going to train data to define the cluster of MaterialType."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Retrieve Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's say we going to train \n",
    "\n",
    "datas=spark.sql(\"SELECT MaterialType,sum(Checkouts) as Total FROM libchecksout GROUP BY MaterialType LIMIT 10000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------+\n",
      "|       MaterialType|   Total|\n",
      "+-------------------+--------+\n",
      "|          MICROFORM|     178|\n",
      "|              GLOBE|     741|\n",
      "|REGPRINT, SOUNDDISC|     412|\n",
      "|               BOOK|54356026|\n",
      "|      ER, VIDEOCASS|       3|\n",
      "|           VIDEOREC|    1943|\n",
      "|        UNSPECIFIED|     320|\n",
      "| PICTURE, VIDEODISC|      34|\n",
      "|          MAP, VIEW|       2|\n",
      "|            SECTION|       3|\n",
      "+-------------------+--------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "datas.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datas.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Assembling Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------+-------------+\n",
      "|        MaterialType|   Total|     features|\n",
      "+--------------------+--------+-------------+\n",
      "|           MICROFORM|     178|      [178.0]|\n",
      "|               GLOBE|     741|      [741.0]|\n",
      "| REGPRINT, SOUNDDISC|     412|      [412.0]|\n",
      "|                BOOK|54356026|[5.4356026E7]|\n",
      "|       ER, VIDEOCASS|       3|        [3.0]|\n",
      "|            VIDEOREC|    1943|     [1943.0]|\n",
      "|         UNSPECIFIED|     320|      [320.0]|\n",
      "|  PICTURE, VIDEODISC|      34|       [34.0]|\n",
      "|           MAP, VIEW|       2|        [2.0]|\n",
      "|             SECTION|       3|        [3.0]|\n",
      "|                SONG| 1311618|  [1311618.0]|\n",
      "|           SOUNDCASS|  330665|   [330665.0]|\n",
      "|            COMPFILE|      22|       [22.0]|\n",
      "|        NONPROJGRAPH|       1|        [1.0]|\n",
      "|                 KIT|   43737|    [43737.0]|\n",
      "|SOUNDCASS, VIDEOCASS|      47|       [47.0]|\n",
      "|              VISUAL|  110539|   [110539.0]|\n",
      "|               CHART|       4|        [4.0]|\n",
      "|        ER, VIDEOREC|     305|      [305.0]|\n",
      "|           VIDEODISC|28766230| [2.876623E7]|\n",
      "+--------------------+--------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Assembling Vector\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "assembler = VectorAssembler(\n",
    "    inputCols=[\"Total\"],\n",
    "    outputCol='features')\n",
    "\n",
    "datas = assembler.transform(datas)\n",
    "datas.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Training Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model\n",
    "from pyspark.ml.clustering import KMeans\n",
    "from pyspark.ml.evaluation import ClusteringEvaluator\n",
    "\n",
    "kmeans = KMeans().setK(2).setSeed(1)\n",
    "model = kmeans.fit(datas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------+-------------+----------+\n",
      "|       MaterialType|   Total|     features|prediction|\n",
      "+-------------------+--------+-------------+----------+\n",
      "|          MICROFORM|     178|      [178.0]|         0|\n",
      "|              GLOBE|     741|      [741.0]|         0|\n",
      "|REGPRINT, SOUNDDISC|     412|      [412.0]|         0|\n",
      "|               BOOK|54356026|[5.4356026E7]|         1|\n",
      "|      ER, VIDEOCASS|       3|        [3.0]|         0|\n",
      "+-------------------+--------+-------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Make a prediction\n",
    "predictions = model.transform(datas)\n",
    "predictions.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Silhouette with squared euclidean distance = 0.9779913142714661\n"
     ]
    }
   ],
   "source": [
    "# Evaluate clustering by computing Silhouette score\n",
    "evaluator = ClusteringEvaluator()\n",
    "\n",
    "silhouette = evaluator.evaluate(predictions)\n",
    "print(\"Silhouette with squared euclidean distance = \" + str(silhouette))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vizualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pixiedust database opened successfully\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <div style=\"margin:10px\">\n",
       "            <a href=\"https://github.com/ibm-watson-data-lab/pixiedust\" target=\"_new\">\n",
       "                <img src=\"https://github.com/ibm-watson-data-lab/pixiedust/raw/master/docs/_static/pd_icon32.png\" style=\"float:left;margin-right:10px\"/>\n",
       "            </a>\n",
       "            <span>Pixiedust version 1.1.15</span>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table SPARK_PACKAGES created successfully\n"
     ]
    }
   ],
   "source": [
    "import pixiedust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "pixiedust": {
     "displayParams": {
      "clusterby": "features",
      "handlerId": "scatterPlot",
      "keyFields": "Total",
      "legend": "false",
      "mpld3": "false",
      "rowCount": "3000",
      "valueFields": "prediction",
      "ylabel": "true"
     }
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">.pd_warning{display:none;}</style><div class=\"pd_warning\"><em>Hey, there's something awesome here! To see it, open this notebook outside GitHub, in a viewer like Jupyter</em></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "pixieapp_metadata": null
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![cluster](../Resource/clustering_histogram.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![cluster](../Resource/clustering_line_chart.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
